%!TEX program = pdflatex
%!BIB program = bibtex
\documentclass[]{book}
\usepackage[totalwidth=480pt, totalheight=680pt]{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{array}
\usepackage{multirow}
\usepackage{minted}
\hypersetup{
    colorlinks,
    linkcolor={black},
    citecolor={green!80!black},
    urlcolor={blue!80!black}
}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\ifPDFTeX
   	\usepackage[T1]{fontenc}
   	\usepackage{mathpazo}
\else
   	\usepackage{fontspec}
\fi

\usepackage{amsfonts}

\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics
\usepackage[english]{babel}
\usepackage{tocvsec2}
\setcounter{tocdepth}{4}  % Show headings upto level 4 (1.1.1.1)
% \setcounter{secnumdepth}{4}  % Show 1.1.1.1

\usepackage{listings}

\newcommand{\rulesep}{\unskip\ \vrule\ }

%opening
\title{Dense Video Captioning}

\author{Ganadhish Acharekar, Akshat Shah, Arnav Shah, Saharsh Jain}



\begin{document}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begin{titlepage} % Suppresses displaying the page number on the title page and the subsequent page counts as page 1
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for horizontal lines, change thickness here
	
	\center % Centre everything on the page
	
	%------------------------------------------------
	%	Headings
	%------------------------------------------------

	\includegraphics[width=0.2\textwidth]{assets/img/vjti.png}\\[1cm] % Include a department/university logo - this will require the graphicx package	

	\textsc{\LARGE Veermata Jijabai Technological Institute}\\[1.5cm] % Main heading such as the name of your university/college
	
	\textsc{\Large Bachelor of Technology (Information Technology)}\\[0.5cm] % Major heading such as course name
	
	\textsc{\Large Project Report}\\[0.5cm] % Major
	
	\textsc{\large Department of Computer Engineering \& Information Technology}\\[0.5cm] % Minor heading such as course title
	
	%------------------------------------------------
	%	Title
	%------------------------------------------------
	
	\HRule\\[0.4cm]
	
	{\huge\bfseries Dense Video Captioning}\\[0.4cm] % Title of your document
	
	\HRule\\[1.5cm]
	
	%------------------------------------------------
	%	Author(s)
	%------------------------------------------------
	
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft}
			\large
			Ganadhish Acharekar\\
			Akshat Shah\\
			Arnav Shah\\
			Saharsh Jain
		\end{flushleft}
	\end{minipage}
	~
	\begin{minipage}{0.4\textwidth}
		\begin{flushright}
			\large
			\textit{Project Supervisor}\\
			Prof. Sandip T. Shingade
		\end{flushright}
	\end{minipage}
	
	% If you don't want a supervisor, uncomment the two lines below and comment the code above
	%{\large\textit{Author}}\\
	%John \textsc{Smith} % Your name
	
	%------------------------------------------------
	%	Date
	%------------------------------------------------
	
%%	\vfill\vfill\vfill % Position the date 3/4 down the remaining page
	
%%	{\large\today} % Date, change the \today to a set date if you want to be precise
	
	%------------------------------------------------
	%	Logo
	%------------------------------------------------
	
	%\vfill\vfill
	 
	%----------------------------------------------------------------------------------------
	
	\vfill % Push the date up 1/4 of the remaining page
	
\end{titlepage}

\include{certificate.tex}
\include{approval.tex}
\include{declaration.tex}
\include{acknowledgements.tex}



\chapter*{Abstract}
\par The task of Dense Video Captioning (DVC), featured in the annual ActivityNet competition, aims to localize the different events in a given video and generate natural language descriptions for each of them. Most literature for this task involves utilizing CNN extracted video features and multiple stages of training. These stages of training include separately training the proposal module to predict event timestamps in a video, followed by training the captioning module on only the predicted event features.
\par This project aims to utilize multiple modalities, namely audio and video, as opposed to previous single modality approaches thereby assisting the video features in making sharp distinctions between foreground and background events through audio cues. We propose a model architecture that can be trained end-to-end by incorporating a differentiable context mask that allows joint and uniform learning between the decoder and captioning module. We utilize the transformer architecture and an efficient deformable attention mechanism for proposal generation which works with multi-scale features and attends to a set of tokens around a reference point, rather than attending to all tokens in the sequence (quadratic time complexity). Additionally, we increase the model's efficiency by using a smaller set of tokens from the input sequence through a scoring network to mask unncessary tokens in the encoder. Based on this, we can select what percentage of the tokens are needed by the model as a hyperparameter. Lastly, we use a transformer decoder as the captioning module instead traditional RNN-based models used previously to avoid the problem of long term dependency and allow parallelism of FLOPs in the attention heads. The captioning module predicts next-word probabilities across the entire vocabulary, for each event in the video and is evaluated using a multitude of metrics.
\par We also adopt a novel temporally sensitive pretraining strategy for multiple modalities to optimize the feature extractors for the task of dense video captioning. It enhances the features space of the video, allowing the features to differentiate between foreground and background clips, thereby improving the prediction of multiple events across the video. Following this, we provide detailed qualitative and quantitative analysis of our multimodal features.
\par  We evaluate our model on two sub-tasks, namely, event localization and dense caption generation as part of the task of dense video captioning. The combination of these sub-tasks makes the overall objective challenging to achieve and leads the models to be complex and compute and time intensive when training. We train our model on the ActivityNet dataset, which is the largest dense video captioning dataset consisting of 20k videos from YouTube, released as part of the ActivityNet challenge in 2017. We report competitive results against previous CNN and transformer-based models and provide an in-depth analysis into our methodologies, architecture and outcome. \newline

\input{content/key-terms.tex}



\tableofcontents

\newpage
\begingroup
\let\cleardoublepage\relax
\listoffigures
\endgroup

\begingroup
\let\cleardoublepage\relax
\listoftables
\endgroup



% \thispagestyle{empty}
% \listoffigures
% \listoftables



\chapter{Introduction}
\input{content/intro-basics.tex}
\input{content/problem-background.tex}
\input{content/problem-formulation.tex}
\input{content/objectives.tex}

\chapter{Literature Review}
\input{content/literature-review.tex}


\chapter{Architecture}
\input{content/architecture.tex}

% section
\input{content/feature-extraction/feature-extraction.tex}

\chapter{Experimentation and Results}
\input{content/experimentation.tex}

\chapter{Conclusion and Future Work}
\input{content/conclusion.tex}
\input{content/future_work.tex}

\appendix
\settocdepth{section}


% \chapter{Supplementary Details}
% Include individual suppl-detail file here
% Use section as the top level section in that .tex file


\chapter{Paper Summaries}
% Include individual paper summaries here
% Use section as the top level section in that .tex file
\input{paper-summaries/krishna2017densecaptioning.tex}
\newpage
\input{paper-summaries/bmt.tex}
\newpage
\input{paper-summaries/vit.tex}
\newpage
\input{paper-summaries/vivit.tex}
\newpage
\input{paper-summaries/ast.tex}
\newpage
\input{paper-summaries/alwassel2021tsp.tex}
\newpage
\input{paper-summaries/wang2021endtoend.tex}
\newpage
\input{paper-summaries/detr.tex}
\newpage
\input{paper-summaries/deformable-detr.tex}
\newpage
\input{paper-summaries/sparse-detr.tex}


\newpage
\bibliographystyle{unsrt}
\bibliography{references.bib}

\end{document}
