\subsection{Problem Background}

\par There has been a significant progress in the fields of \textit{Computer Vision} (CV) and \textit{Natural Language Processing} (NLP) and other artificial intelligence problems in recent decades. In computer vision, tasks like object detection and classification are well-explored, while in natural language processing, sequence to sequence tasks like machine translation have been well worked upon. The most promising solutions to these tasks come from deep learning methodologies, outperforming techniques like rule-based systems and other traditional machine learning algorithms. Owing to the rich feature representation capabilities of different kinds of neural networks, tasks that are more natural to humans are becoming solvable by machines, especially perceptive and understanding tasks.

\par The task of image captioning combines the fields of CV and NLP. Video action recognition, which involves classifying the action in a short video clip, is a task that can be considered as the representative task for video understanding. Taking one step further from action recognition and image captioning, the task of video captioning involves labelling a video clip with a single natural language sentence. However, for long videos, a single sentence is not enough to describe all events that may occur in a video. Thus, the task of \textbf{Dense Video Captioning (DVC)} was introduced \cite{krishna2017densecaptioning}. It involves generating natural language descriptions for each of the multiple events that may occur in a video.

\par Describing a short video in natural language is trivial for humans, but a challenging task for machines. Automatic video description involves understanding of many entities and the detection of their occurrences in a video employing computer vision techniques. These entities include background scene, humans, objects, human actions, human-object interactions, human-human interactions, other events, and the order in which events occur. All this information should then be articulated using comprehensible and grammatically correct text, employing NLP techniques\cite{aafaq2020video}. Indeed, the task of dense video captioning can be thought of as the culmination of all the perceptive learning tasks of computer vision and the natural language generation task.

\par As we move towards a digital age, more and more content is generated in the form of multimedia, e.g., videos. The applications of dense video captioning are in tasks such as:

\begin{itemize}
	\item Video summarization and highlights generation, e.g. in fields such as sports and entertainment
	\item Video retrieval via search and indexing on its dense captions. This can help in a multitude of areas such as experiments, surveillance and security, sports, education, et cetera.
	\item Video segment localization queries can be better handled by using dense event captions generated on a bulk of videos. Indeed, this can open the door to automatic interpretation of videos, a kind of data that is treated as unstructured binary data today.
	\item Increased accessibility to the visually impaired can be achieved with the combined use of DVC and the much more mature task of text-to-speech (TTS).
\end{itemize}
